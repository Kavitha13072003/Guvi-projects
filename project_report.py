# -*- coding: utf-8 -*-
"""project_report

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M3nTxfYXtA9TEdJX5H0Yy5Ru64wRlSEu
"""

import streamlit as st
import pandas as pd

# Title for the app
st.title("Clickstream Data Upload App")

# File upload widget
uploaded_file = st.file_uploader("Upload your CSV file", type=["csv"])

# If a file is uploaded
if uploaded_file is not None:
    # Read the uploaded CSV into a pandas DataFrame
    data = pd.read_csv(uploaded_file)

    # Display the uploaded data
    st.write("Uploaded Data:")
    st.dataframe(data)

    # Display first 5 rows
    st.write("First 5 Rows of Data:")
    st.write(data.head())
else:
    st.write("Please upload a CSV file to begin.")

from google.colab import files
uploaded = files.upload()

import pandas as pd

# Read CSV from full file path
df = pd.read_csv("/content/e-shop clothing 2008.csv")

# Show first 5 rows
print(df.head())

import os
print(os.getcwd())

# Check for null values in each column
print(df.isnull().sum())

print(df.columns)

from google.colab import files
uploaded = files.upload()

import pandas as pd

# Use the exact uploaded file name
df = pd.read_csv("/content/e-shop clothing 2008.csv", sep=';')

# Check columns
print(df.columns)

# Check for missing values in each column
print(df.isnull().sum())

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

# List of categorical columns to encode
cat_cols = ['colour', 'country', 'page 1 (main category)', 'model photography', 'location']

# Apply LabelEncoder to each
for col in cat_cols:
    df[col] = le.fit_transform(df[col])

# Check first 5 rows to confirm changes
print(df.head())

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

# List of numeric columns to scale
num_cols = ['price']

# Apply scaler
df[num_cols] = scaler.fit_transform(df[num_cols])

# Confirm scaling
print(df.head())

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10,5))
sns.countplot(x='country', data=df)
plt.title("Session Count by Country")
plt.xticks(rotation=90)
plt.show()

print(df.dtypes)

# Exclude 'page 2 (clothing model)' and select only numeric columns
numeric_df = df.drop(columns=['page 2 (clothing model)'])

# Plot correlation heatmap
plt.figure(figsize=(12,8))
sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

df['page 2 (clothing model)'] = le.fit_transform(df['page 2 (clothing model)'])

# Drop session ID (it's just an identifier, not useful for clustering)
X = df.drop(columns=['session ID'])

from sklearn.cluster import KMeans

# Create KMeans model with 3 clusters (you can try different numbers later)
kmeans = KMeans(n_clusters=3, random_state=42)

# Fit the model
kmeans.fit(X)

# Add cluster labels to your DataFrame
df['cluster'] = kmeans.labels_

# See cluster counts
print(df['cluster'].value_counts())

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Reduce to 2 dimensions for plotting
pca = PCA(2)
X_pca = pca.fit_transform(X)

# Create scatter plot
plt.figure(figsize=(8,6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['cluster'], cmap='viridis')
plt.title("Customer Segments using K-Means Clustering")
plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.colorbar(label='Cluster')
plt.show()

# Group by cluster and get mean of numeric columns
cluster_profile = df.groupby('cluster').mean()

# Display the profile
print(cluster_profile)

print(df['cluster'].value_counts())

for i in df['cluster'].unique():
    popular_country = df[df['cluster'] == i]['country'].value_counts().idxmax()
    print(f"Most popular country in cluster {i} is: {popular_country}")

for i in df['cluster'].unique():
    popular_category = df[df['cluster'] == i]['page 1 (main category)'].value_counts().idxmax()
    print(f"Most popular category in cluster {i} is: {popular_category}")

for i in df['cluster'].unique():
    avg_price = df[df['cluster'] == i]['price'].mean()
    print(f"Average price in cluster {i}: {avg_price:.2f}")

import seaborn as sns
import matplotlib.pyplot as plt

# Count of customers in each cluster
plt.figure(figsize=(6,4))
sns.countplot(x='cluster', data=df, palette='viridis')
plt.title("Number of Customers in Each Cluster")
plt.xlabel("Cluster")
plt.ylabel("Number of Customers")
plt.show()

# Create a DataFrame of average price per cluster
avg_price_per_cluster = df.groupby('cluster')['price'].mean().reset_index()

# Plot
plt.figure(figsize=(6,4))
sns.barplot(x='cluster', y='price', data=avg_price_per_cluster, palette='viridis')
plt.title("Average Price per Cluster")
plt.xlabel("Cluster")
plt.ylabel("Average Price")
plt.show()

# Find most popular product category in each cluster
popular_category_per_cluster = df.groupby('cluster')['page 1 (main category)'].agg(lambda x: x.value_counts().index[0]).reset_index()

# Plot
plt.figure(figsize=(6,4))
sns.barplot(x='cluster', y='page 1 (main category)', data=popular_category_per_cluster, palette='viridis')
plt.title("Most Popular Product Category per Cluster")
plt.xlabel("Cluster")
plt.ylabel("Most Popular Category")
plt.show()

# Find most popular country in each cluster
popular_country_per_cluster = df.groupby('cluster')['country'].agg(lambda x: x.value_counts().index[0]).reset_index()

# Plot
plt.figure(figsize=(6,4))
sns.barplot(x='cluster', y='country', data=popular_country_per_cluster, palette='viridis')
plt.title("Most Popular Country per Cluster")
plt.xlabel("Cluster")
plt.ylabel("Most Popular Country")
plt.show()

# Drop target 'price' from features
X = df.drop(columns=['price', 'cluster', 'session ID'])

# Set target variable
y = df['price']

from sklearn.model_selection import train_test_split

# Split 80% for training, 20% for testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LinearRegression

# Create and train model
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

y_pred = lr_model.predict(X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

print("Mean Absolute Error (MAE):", mean_absolute_error(y_test, y_pred))
print("Mean Squared Error (MSE):", mean_squared_error(y_test, y_pred))
print("R2 Score:", r2_score(y_test, y_pred))

plt.figure(figsize=(6,4))
plt.scatter(y_test, y_pred, color='purple')
plt.title("Actual vs Predicted Product Prices")
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.grid(True)
plt.show()

# Number of clicks per session  #feature engineering
session_clicks = df.groupby('session ID').size().reset_index(name='click_count')

# Merge back to original DataFrame
df = df.merge(session_clicks, on='session ID', how='left')

# Check it out
print(df[['session ID', 'click_count']].head())

category_views = df.groupby('session ID')['page 1 (main category)'].nunique().reset_index(name='unique_categories_viewed')

# Merge back
df = df.merge(category_views, on='session ID', how='left')

# Check it out
print(df[['session ID', 'unique_categories_viewed']].head())

session_value = df.groupby('session ID')['price'].sum().reset_index(name='total_session_value')

# Merge back
df = df.merge(session_value, on='session ID', how='left')

# Check it out
print(df[['session ID', 'total_session_value']].head())

# Drop 'price', 'cluster', 'session ID', and 'page 2 (clothing model)' (non-numeric) from features
X = df.drop(columns=['price', 'cluster', 'session ID', 'page 2 (clothing model)'])

# Set target variable
y = df['price']

# Check final feature columns
print(X.columns)

from sklearn.model_selection import train_test_split

# Split 80% train and 20% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LinearRegression

# Create and train model
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

y_pred = lr_model.predict(X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

print("Mean Absolute Error (MAE):", mean_absolute_error(y_test, y_pred))
print("Mean Squared Error (MSE):", mean_squared_error(y_test, y_pred))
print("R2 Score:", r2_score(y_test, y_pred))

import matplotlib.pyplot as plt

plt.figure(figsize=(6,4))
plt.scatter(y_test, y_pred, color='green')
plt.title("Actual vs Predicted Product Prices (With New Features)")
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.grid(True)
plt.show()

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.cluster import KMeans
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Title
st.title("📊 Clickstream Customer Conversion Project Report")

# File Upload
uploaded_file = st.file_uploader("Upload your preprocessed CSV file", type=['csv'])
if uploaded_file is not None:
    df = pd.read_csv(uploaded_file, sep=';')
    st.write("### 📑 Dataset Preview")
    st.dataframe(df.head())

    # EDA: Value counts for 'country'
    st.write("### 📊 Country Distribution")
    fig1, ax1 = plt.subplots()
    sns.countplot(x='country', data=df, ax=ax1)
    plt.xticks(rotation=90)
    st.pyplot(fig1)

    # EDA: Price Distribution
    st.write("### 📊 Price Distribution")
    fig2, ax2 = plt.subplots()
    sns.histplot(df['price'], kde=True, ax=ax2)
    st.pyplot(fig2)

    # Feature Engineering: Click count per session
    session_clicks = df.groupby('session ID').size().reset_index(name='click_count')
    df = df.merge(session_clicks, on='session ID', how='left')

    # Clustering
    st.write("### 📈 K-Means Clustering (3 Segments)")
    X_clust = df.drop(columns=['price', 'session ID', 'page 2 (clothing model)'])
    kmeans = KMeans(n_clusters=3, random_state=42)
    kmeans.fit(X_clust)
    df['cluster'] = kmeans.labels_
    st.dataframe(df[['session ID', 'cluster']].head())

    # Cluster distribution
    fig3, ax3 = plt.subplots()
    sns.countplot(x='cluster', data=df, palette='viridis', ax=ax3)
    st.pyplot(fig3)

    # Regression
    st.write("### 📉 Regression Model: Predicting Product Price")
    X = df.drop(columns=['price', 'session ID', 'page 2 (clothing model)', 'cluster'])
    y = df['price']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    st.write("#### 📏 Regression Metrics:")
    st.write("MAE:", mean_absolute_error(y_test, y_pred))
    st.write("MSE:", mean_squared_error(y_test, y_pred))
    st.write("R² Score:", r2_score(y_test, y_pred))

    # Actual vs Predicted Plot
    st.write("#### 📊 Actual vs Predicted Price")
    fig4, ax4 = plt.subplots()
    ax4.scatter(y_test, y_pred, color='blue')
    ax4.set_xlabel("Actual Price")
    ax4.set_ylabel("Predicted Price")
    ax4.set_title("Actual vs Predicted Product Price")
    st.pyplot(fig4)

    # Project Summary
    st.write("### 📌 Project Summary:")
    st.write("""
    ✅ Data Preprocessing: Cleaned missing values, encoded categorical columns, scaled numeric values
    ✅ EDA: Visualized country-wise sessions and price distributions
    ✅ Feature Engineering: Created click counts per session
    ✅ Clustering: Segmented customers into 3 groups based on behavior
    ✅ Regression: Built and evaluated a model to predict product price
    """)

else:
    st.write("⬆️ Please upload your CSV file to view the report.")